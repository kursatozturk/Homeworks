{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification with Cross Entropy Loss\n",
    "\n",
    "In this exercise, you will implement and train a linear classifier using cross entropy loss. We will reuse most of the code (and the cells) that we developed in Task 1.\n",
    "\n",
    "Please complete all cells and answer questions asked in the cells if you want to get a full grade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST Dataset\n",
    "\n",
    "MNIST (http://yann.lecun.com/exdb/mnist/) is one of the popular datasets used for testing machine learning models. It contains hand-written digits as grayscale images with 28x28 resolution. There are 60,000 samples for training (10,000 of which is usually used for validation), and 10,000 for testing. Although there are more challenging datasets available, MNIST is a good starting point for testing early versions of the models and as a sanity check.\n",
    "\n",
    "Since more challenging datasets require more memory and lead to bigger models that require more computational power, we will stick with the MNIST dataset for the first HW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 784)\n",
      "Training labels shape:  (50000,)\n",
      "Validation data shape:  (10000, 784)\n",
      "Validation labels shape:  (10000,)\n",
      "Test data shape:  (10000, 784)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# First run the \"get_data.sh\" under metu/data/ in your terminal.\n",
    "# Then this cell will load the raw MNIST data.\n",
    "#\n",
    "#\n",
    "from ceng783.utils import load_mnist\n",
    "mnist_file = 'ceng783/data/mnist.pkl.gz'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(mnist_file)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print 'Training data shape: ', X_train.shape\n",
    "print 'Training labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (9999, 784)\n",
      "Train labels shape:  (9999,)\n",
      "Validation data shape:  (999, 784)\n",
      "Validation labels shape:  (999,)\n",
      "Test data shape:  (999, 784)\n",
      "Test labels shape:  (999,)\n"
     ]
    }
   ],
   "source": [
    "# Subsample the data for faster experiments in this exercise.\n",
    "num_training = 10000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "\n",
    "X_train = X_train[1:num_training]\n",
    "y_train = y_train[1:num_training]\n",
    "\n",
    "X_val = X_val[1:num_validation]\n",
    "y_val = y_val[1:num_validation]\n",
    "\n",
    "X_test = X_test[1:num_test]\n",
    "y_test = y_test[1:num_test]\n",
    "\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f80d7ba50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEQVJREFUeJzt3VuIned1xvFnWWdpdPRIo7EsRT5RWgx1ijAFl+ISHNwScHIRE18UFUKUixgayEWNb+KbgilN0lwFFCwiQ+IkkLj2RWhjTMEtFGPZmNiJG9sIyZ5qLNkanazT6LB6MdtlYs9ea3t/+zSz/j8QM7PXfHu/s0fPfHtmfe/7mrsLQD03DHsAAIaD8ANFEX6gKMIPFEX4gaIIP1AU4QeKIvxAUYQfKGr5IB/MzLicEOgzd7dOPq/Rmd/M7jez35vZ22b2SJP7AjBY1u21/Wa2TNKbku6TNCXpJUkPufvvgmM48wN9Nogz/92S3nb3w+4+K+mnkh5ocH8ABqhJ+HdIenfex1Ot2/6Ame0zs0NmdqjBYwHosSZ/8FvopcUnXta7+35J+yVe9gOjpMmZf0rSznkf3yzpWLPhABiUJuF/SdIdZnaLma2U9BVJz/ZmWAD6reuX/e5+1cwelvTvkpZJOuDuv+3ZyAD0Vdetvq4ejN/5gb4byEU+ABYvwg8URfiBogg/UBThB4oi/EBRA53Pj+6YddS56erYrH7DDfH5ocnxWZs5q1+/fr3renZsBZz5gaIIP1AU4QeKIvxAUYQfKIrwA0XR6huApu22ZcuWdV1fvjz+Fq9YsSKsZ8dn9ehry9pts7Ozfatfu3YtPDYb2yBnw/YLZ36gKMIPFEX4gaIIP1AU4QeKIvxAUYQfKIo+f4eifnU27TXrha9cuTKsr1mzJqyvXbu2bW3jxo3hsVl9/fr1YT0bW/S8Xbp0KTz2zJkzYX1mZiasnzp1qm3tww8/DI+9fPlyWL9y5UpYXwzXCXDmB4oi/EBRhB8oivADRRF+oCjCDxRF+IGiGvX5zeyIpHOSrkm66u57ejGoYch69dGc+axPH/XhpbyXvmXLlrC+ffv2trXJycnw2JtvvjmsT0xMhPVs7JGzZ8+G9WPHjoX1o0ePdl1/7733wmOjawQk6fz582E9W2vg6tWrbWuDugagFxf5/JW7f9CD+wEwQLzsB4pqGn6X9Gsze9nM9vViQAAGo+nL/nvc/ZiZbZP0nJn9j7u/MP8TWj8U+MEAjJhGZ353P9Z6e0LS05LuXuBz9rv7nsX8x0BgKeo6/Ga2zszWf/S+pM9Ler1XAwPQX01e9k9Iero1ZXO5pJ+4+7/1ZFQA+q7r8Lv7YUl/2sOx9FWTPr4U9/LHxsbCYzdt2hTWs176zp07w/ru3bu7qknSLbfcEtZvuummsJ597VE/O5uPPzU1FdY3bNgQ1qPvabZXQtPtwZscn+0p0Cu0+oCiCD9QFOEHiiL8QFGEHyiK8ANFLZmlu7PWTdPltVevXt22lrW7xsfHw/quXbvC+u233x7Wb7vttra1W2+9NTx2x44dYT1rU2ZbfEetvug5lfLvSdYSu3DhQlc1KV/a++LFi2E9m9IbLf09qGW/OfMDRRF+oCjCDxRF+IGiCD9QFOEHiiL8QFH0+VuyfnXUk86Wr876/Nny2tl1AFE9e+zsecu2yc62qm6ytfmqVavCejald/PmzW1r2dbk2XLr2dibGNTS3Zz5gaIIP1AU4QeKIvxAUYQfKIrwA0URfqCoJdPnzzRduju6DmDdunXhsVlPOevFZ1t0R9cgZNtgT09Ph/Vs3ns2p37NmjVta9nzkn3Psnnv2TUMTe47+7qjdQw6uf9B4MwPFEX4gaIIP1AU4QeKIvxAUYQfKIrwA0WlfX4zOyDpC5JOuPudrdu2SPqZpN2Sjkh60N1P9W+Y/Zf1hKPrALL15bO54Vk9uwYhWmP+1Kn423Ly5MmwfunSpbCezbmP5tRnz1v2dWdja7Juf3bfWR8/uw5gsfT5fyTp/o/d9oik5939DknPtz4GsIik4Xf3FyTNfOzmByQdbL1/UNIXezwuAH3W7e/8E+4+LUmtt9t6NyQAg9D3a/vNbJ+kff1+HACfTrdn/uNmNilJrbcn2n2iu+939z3uvqfLxwLQB92G/1lJe1vv75X0TG+GA2BQ0vCb2VOS/lvSH5nZlJl9VdLjku4zs7ck3df6GMAikv7O7+4PtSl9rsdj6atsLfSsHl0HsHLlyvDYbB/6rFeeidbWP3Gi7W9kkvL5/tn1D9nYo3UQsj5+1kvPevXR13bu3Lnw2NnZ2bA+Cn36prjCDyiK8ANFEX6gKMIPFEX4gaIIP1DUklm6u5+tPCmefpq18qLlqzs5Pht71JbKppZmbcpNmzaF9a1bt4b17du3t61lX/fp06fDetbqi6Y6Z1N2s+ct02TZ8EHhzA8URfiBogg/UBThB4oi/EBRhB8oivADRS2ZPn+maZ8/6odn/eqsni1hnYnGPjY2Fh6bbZMd9eklaWJiouv7v3jxYnhs1ufPevXR9Q9Np+Rm24fT5wcwsgg/UBThB4oi/EBRhB8oivADRRF+oKgl0+fP+viZrNce9fmz5auz+87mjmf16P7Hx8fDY3ft2hXWJycnw3p2/9H3pek21k3m3GfLhmd9+sXQx89w5geKIvxAUYQfKIrwA0URfqAowg8URfiBotI+v5kdkPQFSSfc/c7WbY9J+pqk91uf9qi7/6pfg+yFJuvyZ/VsbnfWr862g758+XJYj7bBXr9+fXhsVs/2HMie12jOfTafv+na+tH3JRt3dh3AUtDJmf9Hku5f4PbvuftdrX8jHXwAn5SG391fkDQzgLEAGKAmv/M/bGa/MbMDZra5ZyMCMBDdhv8Hkm6TdJekaUnfafeJZrbPzA6Z2aEuHwtAH3QVfnc/7u7X3P26pB9Kujv43P3uvsfd93Q7SAC911X4zWz+VK8vSXq9N8MBMCidtPqeknSvpHEzm5L0bUn3mtldklzSEUlf7+MYAfRBGn53f2iBm5/ow1gayfq2WS++SZ8/W0sg61efO3curGf97KgXv27duvDYaA97SVq7dm1Yv3LlSlg/f/5829rMTNxEunDhQlhvuhdDk/tuun7EKOAKP6Aowg8URfiBogg/UBThB4oi/EBRS2bp7qZTNLNWX3R8NmU3a1mdOXMmrGdTeqN61pLKWqCZaElzKR5b1uLMpjpnz3v0tWfPS9NlxTPR/9dBtRE58wNFEX6gKMIPFEX4gaIIP1AU4QeKIvxAUWX6/E2m7Gb17LGvXr0a1rMpv1kvPnr87PqG7BqEbMrv6tWrw3rUD286JTfrtUfXGGTXTmRTlbPvadPrAAaBMz9QFOEHiiL8QFGEHyiK8ANFEX6gKMIPFFWmz990Pn80bz3aIluSVq1aFdazXnm2fHZ0fNMturPHzubzR/3w7PqFrJfe5BqF7Njs2oumff5RWPqbMz9QFOEHiiL8QFGEHyiK8ANFEX6gKMIPFJX2+c1sp6QnJW2XdF3Sfnf/vpltkfQzSbslHZH0oLuf6t9Q03GG9abrtEeyPv7Y2FhY37JlS1jftGlTWN+4cWPb2o033hgeu3Xr1rCebfGd9bNPnz7dtnbx4sXw2FOn4v9OH3zwQdfHZ3slZGPL+vyLYYvvTs78VyV9y93/WNKfS/qGmf2JpEckPe/ud0h6vvUxgEUiDb+7T7v7K633z0l6Q9IOSQ9IOtj6tIOSvtivQQLovU/1O7+Z7Zb0WUkvSppw92lp7geEpG29HhyA/un42n4zG5P0C0nfdPez2e/Y847bJ2lfd8MD0C8dnfnNbIXmgv9jd/9l6+bjZjbZqk9KOrHQse6+3933uPueXgwYQG+k4be5U/wTkt5w9+/OKz0raW/r/b2Snun98AD0Sycv+++R9LeSXjOzV1u3PSrpcUk/N7OvSnpH0pf7M8TOZC2npstnR/XsvrPpxFGrTpImJibC+rZt7f/ckrX6sim9WUsqa8fNzMy0rb3zzjvhsYcPHw7r2fHHjx9vW8u2B8+W9l4KS3en4Xf3/5LU7hf8z/V2OAAGhSv8gKIIP1AU4QeKIvxAUYQfKIrwA0UtmaW7s3501rfN+r7vv/9+21o2ZTfr44+Pj4f1JtM/s350NrX17NmzYX16ejqsv/XWW21rb775Znhs1ud/9913w/rJkyfb1s6fPx8eOzs7G9azKeCjMGU3w5kfKIrwA0URfqAowg8URfiBogg/UBThB4paMn3+pvP5s75vNDe86WNfuXIlrGfXKETLY2dbbGePnc3Xz3rtR44caVs7evRoeGz0nEvx1y3F39N+z9enzw9gZBF+oCjCDxRF+IGiCD9QFOEHiiL8QFE2yH6kmQ2t+ZltL5bVV6xY0ba2Zs2a8NgNGzaE9Ww+f1aP7j8at5T3oy9cuBDWo3X5pbgXn62hkF17kfXqo2sYsj7+Yp6v7+4d7aXHmR8oivADRRF+oCjCDxRF+IGiCD9QFOEHikr7/Ga2U9KTkrZLui5pv7t/38wek/Q1SR8taP+ou/8qua+RbY42uQ5g+fJ4WYSVK1eG9dWrVzc6ftmyZW1r2deVyfrd2fr2UT8967U37cVH9aUwH7+dTvv8nSzmcVXSt9z9FTNbL+llM3uuVfueu/9zt4MEMDxp+N19WtJ06/1zZvaGpB39HhiA/vpUv/Ob2W5Jn5X0Yuumh83sN2Z2wMw2tzlmn5kdMrNDjUYKoKc6Dr+ZjUn6haRvuvtZST+QdJukuzT3yuA7Cx3n7vvdfY+77+nBeAH0SEfhN7MVmgv+j939l5Lk7sfd/Zq7X5f0Q0l392+YAHotDb/N/bn4CUlvuPt3590+Oe/TviTp9d4PD0C/dNLq+wtJ/ynpNc21+iTpUUkPae4lv0s6IunrrT8ORve1aPsnUcssa6dFrThJuuGG+GdwVm/azotk/z+ylllUz+67n/XF3MrLdNrqKzOfvynCvzDCP3qYzw8gRPiBogg/UBThB4oi/EBRhB8oilbfEtfPNqC0tFtmixWtPgAhwg8URfiBogg/UBThB4oi/EBRhB8oqpPVe3vpA0lH53083rptFI3q2D7VuAbchx/V50yqM7bPdPqJA73I5xMPbnZoVNf2G9Wxjeq4JMbWrWGNjZf9QFGEHyhq2OHfP+THj4zq2EZ1XBJj69ZQxjbU3/kBDM+wz/wAhmQo4Tez+83s92b2tpk9MowxtGNmR8zsNTN7ddhbjLW2QTthZq/Pu22LmT1nZm+13i64TdqQxvaYmf1v67l71cz+Zkhj22lm/2Fmb5jZb83s71u3D/W5C8Y1lOdt4C/7zWyZpDcl3SdpStJLkh5y998NdCBtmNkRSXvcfeg9YTP7S0kfSnrS3e9s3fZPkmbc/fHWD87N7v4PIzK2xyR9OOydm1sbykzO31la0hcl/Z2G+NwF43pQQ3jehnHmv1vS2+5+2N1nJf1U0gNDGMfIc/cXJM187OYHJB1svX9Qc/95Bq7N2EaCu0+7+yut989J+mhn6aE+d8G4hmIY4d8h6d15H09ptLb8dkm/NrOXzWzfsAezgImPdkZqvd025PF8XLpz8yB9bGfpkXnuutnxuteGEf6FlhgapZbDPe7+Z5L+WtI3Wi9v0ZmOdm4elAV2lh4J3e543WvDCP+UpJ3zPr5Z0rEhjGNB7n6s9faEpKc1ersPH/9ok9TW2xNDHs//G6WdmxfaWVoj8NyN0o7Xwwj/S5LuMLNbzGylpK9IenYI4/gEM1vX+kOMzGydpM9r9HYfflbS3tb7eyU9M8Sx/IFR2bm53c7SGvJzN2o7Xg/lIp9WK+NfJC2TdMDd/3Hgg1iAmd2qubO9NDfj8SfDHJuZPSXpXs3N+jou6duS/lXSzyXtkvSOpC+7+8D/8NZmbPfqU+7c3KextdtZ+kUN8bnr5Y7XPRkPV/gBNXGFH1AU4QeKIvxAUYQfKIrwA0URfqAowg8URfiBov4Pt2BHom2bGu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing: subtract the mean image\n",
    "# first: compute the image mean based on the training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "# second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "\n",
    "print mean_image[:10] # print a few of the elements\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((28,28))) # visualize the mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 785) (999, 785) (999, 785)\n"
     ]
    }
   ],
   "source": [
    "# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix W.\n",
    "# Also, lets transform both data matrices so that each image is a column.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "\n",
    "print X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier with Cross-entropy Loss\n",
    "\n",
    "Your code for this section will all be written inside **ceng783/linear_classification.py**. \n",
    "\n",
    "Fill in the loss calculation in the `vectorized_xentropy_loss' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.302618\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the naive implementation of the loss we provided for you:\n",
    "from ceng783.linear_classification import *\n",
    "\n",
    "input_size = X_train[0].shape[0]\n",
    "output_size = 10\n",
    "\n",
    "LC = LinearClassifier(input_size, output_size) # initializes the weights to random small numbers\n",
    "\n",
    "loss, _ = LC.vectorized_xentropy_loss(X_train, y_train)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print 'loss: %f' % loss\n",
    "print 'sanity check: %f' % (-np.log(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n",
    "\n",
    "Softmax classifier of cross-entropy function is -log(e^Syi/âˆ‘e^Sj). Which means that it computes minus logarithm of correct class' probability. Since initially weights are random distribution, probabilities are same for all class. In this case, we have 10 class, so it computes one of 10 classes probability, which takes us to the ratio \n",
    "Py/Pall == 1/10. As a result it must be -log(1/10).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Gradient\n",
    "\n",
    "The `grad` returned from the function above is right now all zero. Derive and implement the gradient for the cross entropy loss function and implement it inline inside the function `vectorized_xentropy_loss`. You will find it helpful to interleave your new code inside the existing function.\n",
    "\n",
    "To check that you have correctly implemented the gradient correctly, you can numerically estimate the gradient of the loss function and compare the numeric estimate to the gradient that you computed. We have provided code that does this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.005399 analytic: -0.005399, relative error: 1.736245e-09\n",
      "numerical: 0.001101 analytic: 0.001101, relative error: 2.742857e-10\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.003667 analytic: 0.003667, relative error: 2.812045e-10\n",
      "numerical: 0.000121 analytic: 0.000121, relative error: 8.272483e-08\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: -0.005181 analytic: -0.005181, relative error: 7.245632e-10\n",
      "numerical: 0.000061 analytic: 0.000061, relative error: 1.564761e-07\n",
      "numerical: -0.027179 analytic: -0.027179, relative error: 1.749017e-10\n",
      "numerical: 0.012530 analytic: 0.012530, relative error: 3.264734e-10\n"
     ]
    }
   ],
   "source": [
    "# Once you've implemented the gradient, recompute it with the code below\n",
    "# and gradient check it with the function we provided for you\n",
    "\n",
    "W = 1e-4 * np.random.randn(output_size, input_size)\n",
    "\n",
    "# Compute the loss and its gradient at W.\n",
    "loss, grad = LC.vectorized_xentropy_loss(X_train, y_train, W=W, reg=0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "from ceng783.utils import grad_check_sparse\n",
    "f = lambda w: LC.vectorized_xentropy_loss(X_train, y_train, W=w, reg=0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# You should see differences on the order of 10^-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Linear Classifier with Cross Entropy\n",
    "\n",
    "We now have vectorized and efficient expressions for the loss, the gradient and our gradient matches the numerical gradient. We are therefore ready to do SGD to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 3000: loss 2.302798\n",
      "iteration 100 / 3000: loss 2.199886\n",
      "iteration 200 / 3000: loss 2.097695\n",
      "iteration 300 / 3000: loss 2.075422\n",
      "iteration 400 / 3000: loss 1.971867\n",
      "iteration 500 / 3000: loss 1.888540\n",
      "iteration 600 / 3000: loss 1.872671\n",
      "iteration 700 / 3000: loss 1.822307\n",
      "iteration 800 / 3000: loss 1.875404\n",
      "iteration 900 / 3000: loss 1.859750\n",
      "iteration 1000 / 3000: loss 1.804135\n",
      "iteration 1100 / 3000: loss 1.851184\n",
      "iteration 1200 / 3000: loss 1.731243\n",
      "iteration 1300 / 3000: loss 1.798542\n",
      "iteration 1400 / 3000: loss 1.757437\n",
      "iteration 1500 / 3000: loss 1.706918\n",
      "iteration 1600 / 3000: loss 1.647146\n",
      "iteration 1700 / 3000: loss 1.608022\n",
      "iteration 1800 / 3000: loss 1.711573\n",
      "iteration 1900 / 3000: loss 1.703450\n",
      "iteration 2000 / 3000: loss 1.846117\n",
      "iteration 2100 / 3000: loss 1.700181\n",
      "iteration 2200 / 3000: loss 1.832703\n",
      "iteration 2300 / 3000: loss 1.833048\n",
      "iteration 2400 / 3000: loss 1.647729\n",
      "iteration 2500 / 3000: loss 1.624258\n",
      "iteration 2600 / 3000: loss 1.708581\n",
      "iteration 2700 / 3000: loss 1.729295\n",
      "iteration 2800 / 3000: loss 1.609893\n",
      "iteration 2900 / 3000: loss 1.719545\n",
      "That took 0.705265s\n"
     ]
    }
   ],
   "source": [
    "# Now implement SGD in LinearClassifier.train() function and run it with the code below\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "LC = LinearClassifier(input_size, output_size)\n",
    "\n",
    "stats = LC.train(X_train, y_train, X_val, y_val, learning_rate=0.001, reg=0.5,\n",
    "                      num_iters=3000, batch_size=64, loss='xentropy', verbose=True)\n",
    "toc = time.time()\n",
    "print 'That took %fs' % (toc - tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss value')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.763976\n",
      "validation accuracy: 0.732733\n"
     ]
    }
   ],
   "source": [
    "# Write the LinearSVM.predict function and evaluate the performance on both the\n",
    "# training and validation set\n",
    "y_train_pred = LC.predict(X_train)\n",
    "print 'training accuracy: %f' % (np.mean(y_train == y_train_pred), )\n",
    "y_val_pred = LC.predict(X_val)\n",
    "print 'validation accuracy: %f' % (np.mean(y_val == y_val_pred), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-051266064180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Print out results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (delta, regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of about 0.4 on the validation set.\n",
    "learning_rates = [1e-3, 1e-7, 5e-5]\n",
    "regularization_strengths = [5e-3, 1e-5]\n",
    "\n",
    "# results is dictionary mapping tuples of the form\n",
    "# (delta, learning_rate, regularization_strength) to tuples of the form\n",
    "# (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
    "# of data points that are correctly classified.\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_LC = None # The LinearClassifier object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write code that chooses the best hyperparameters by tuning on the validation #\n",
    "# set. For each combination of hyperparameters, train a linear Classifier on   #\n",
    "# the training set, compute its accuracy on the training and validation sets,  #\n",
    "# and store these numbers in the results dictionary. In addition, store the    #\n",
    "# best validation accuracy in best_val and the LinearClassifier object that    #\n",
    "# achieves this accuracy in best_svm.                                          #\n",
    "#                                                                              #\n",
    "# Hint: You should use a small value for num_iters as you develop your         #\n",
    "# validation code so that the models don't take much time to train; once you   #\n",
    "# are confident that your validation code works, you should rerun the          #\n",
    "# validation  code with a larger value for num_iters.                          #\n",
    "################################################################################\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for rs in regularization_strengths:\n",
    "        LC = LinearClassifier(input_size, output_size)\n",
    "        stats = LC.train(X_train, y_train, X_val, y_val, learning_rate=lr, reg=rs,\n",
    "                  num_iters=2000, batch_size=32, loss='xentropy', verbose=False)\n",
    "        if stats['val_acc_history'][-1] > best_val:\n",
    "            best_val = stats['val_acc_history'][-1]\n",
    "            best_LC = LC\n",
    "        results[(lr, rs)] = stats['train_acc_history'][-1], stats['val_acc_history'][-1]\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy)\n",
    "    \n",
    "print 'best validation accuracy achieved during cross-validation: %f' % best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "# plot training accuracy\n",
    "sz = [results[x][0]*1500 for x in results] # default size of markers is 20\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_scatter, y_scatter, sz)\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('MNIST training accuracy')\n",
    "\n",
    "# plot validation accuracy\n",
    "sz = [results[x][1]*1500 for x in results] # default size of markers is 20\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_scatter, y_scatter, sz)\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('MNIST validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on test set\n",
    "y_test_pred = best_LC.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print 'linear classifier on raw pixels final test set accuracy: %f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned weights for each class.\n",
    "# Depending on your choice of learning rate and regularization strength, these may\n",
    "# or may not be nice to look at.\n",
    "w = best_LC.params['W'][:,:-1] # strip out the bias\n",
    "\n",
    "w = w.reshape(10, 28, 28)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  wimg = 255.0 * (w[i].squeeze() - w_min) / (w_max - w_min)\n",
    "  plt.imshow(wimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
